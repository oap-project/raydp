{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC_Taxi Fare Prediction with RayDp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from raydp.spark import context\n",
    "from raydp.spark.torch.estimator import TorchEstimator\n",
    "from raydp.spark.utils import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, You need to init or connect to a ray cluster. Note that you should set include_java to True\n",
    "# For more config info in ray, please refer the ray doc. https://docs.ray.io/en/latest/package-ref.html\n",
    "# ray.init(address=\"auto\", redis_password=\"123\")\n",
    "ray.init(include_java=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spark session based on Raydp api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After initialize ray cluster, you can use the raydp api to get a spark session\n",
    "spark = context.init_spark(\"raydp use case\", 2, 1, \"5GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and process data based on spark api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then you can operate as you are using spark\n",
    "# The dataset can be downloaded from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(\"/mnt/DP_disk8/nyc_taxi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data\n",
    "# filter data\n",
    "train_data_select = train_data.select(\"pickup_longitude\",\"pickup_latitude\",\"dropoff_longitude\",\"dropoff_latitude\",\"passenger_count\",\"fare_amount\") \\\n",
    "    .filter(train_data['pickup_longitude']<=-73.0) \\\n",
    "    .filter(train_data['pickup_longitude']>=-74.3) \\\n",
    "    .filter(train_data['dropoff_longitude']<=-73.0) \\\n",
    "    .filter(train_data['dropoff_longitude']>=-74.3) \\\n",
    "    .filter(train_data['pickup_latitude']<=41.7) \\\n",
    "    .filter(train_data['pickup_latitude']>=40.6) \\\n",
    "    .filter(train_data['dropoff_latitude']<=41.7) \\\n",
    "    .filter(train_data['dropoff_latitude']>=40.6) \\\n",
    "    .filter(train_data['passenger_count']<=10) \\\n",
    "    .filter(train_data['fare_amount'] >= 0.0) \\\n",
    "    .filter(abs(train_data['dropoff_longitude']-train_data['pickup_longitude'])<=5) \\\n",
    "    .filter(abs(train_data['dropoff_latitude']-train_data['pickup_latitude'])<=5)\n",
    "# add two new features\n",
    "train_data_select = train_data_select.withColumn(\"abs_diff_longitude\", abs(col(\"dropoff_longitude\")-col(\"pickup_longitude\"))) \\\n",
    "                    .withColumn(\"abs_diff_latitude\", abs(col(\"dropoff_latitude\") - col(\"pickup_latitude\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_select.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and evaluation using Raydp with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss function and optimizer\n",
    "class NYC_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NYC_Model, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(7, 14)\n",
    "        self.fc2 = nn.Linear(14, 7)\n",
    "        self.fc3 = nn.Linear(7, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "nyc_model = NYC_Model()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(nyc_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train_dataset and test_dataset\n",
    "train_df, test_df = random_split(train_data_select, [0.7, 0.3])\n",
    "# train_df = train_data_select.sample(False, 0.0005)\n",
    "# test_df = train_data_select.sample(False, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distributed estimator based on the raydp api\n",
    "features = [field.name for field in list(train_data_select.schema) if field.name != \"fare_amount\"]\n",
    "estimator = TorchEstimator(num_workers=4, model=nyc_model, optimizer=optimizer, loss=criterion, \n",
    "                           feature_columns=features, label_column=\"fare_amount\", batch_size=100, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "estimator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "estimator.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutdown raydp and ray\n",
    "estimator.shutdown()\n",
    "context.stop_spark()\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray] *",
   "language": "python",
   "name": "conda-env-ray-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
